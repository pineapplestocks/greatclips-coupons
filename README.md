# Great Clips Coupon Scraper & Website

Automatically scrapes Great Clips coupons from Facebook Ad Library and deploys a searchable website to GitHub Pages.

## üöÄ Features

- **Automated scraping** - Runs daily via GitHub Actions
- **Free hosting** - Deploys to GitHub Pages automatically
- **No server needed** - Everything runs in GitHub's cloud
- **Searchable website** - Filter by state, price, location
- **Universal coupons highlighted** - US-wide coupons shown first

## üìÅ Project Structure

```
‚îú‚îÄ‚îÄ .github/
‚îÇ   ‚îî‚îÄ‚îÄ workflows/
‚îÇ       ‚îî‚îÄ‚îÄ scrape.yml      # GitHub Actions workflow
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ coupons.json        # Scraped coupon data
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îî‚îÄ‚îÄ index.html          # Generated website (GitHub Pages)
‚îú‚îÄ‚îÄ scraper.py              # Main scraper script
‚îú‚îÄ‚îÄ generate_website.py     # Website generator
‚îú‚îÄ‚îÄ template.html           # Website template
‚îî‚îÄ‚îÄ README.md
```

## üõ†Ô∏è Setup Instructions

### Step 1: Create a GitHub Repository

1. Go to [github.com/new](https://github.com/new)
2. Name it something like `greatclips-coupons`
3. Make it **Public** (required for free GitHub Pages)
4. Click **Create repository**

### Step 2: Upload Files

Upload all these files to your new repository:
- `.github/workflows/scrape.yml`
- `scraper.py`
- `generate_website.py`
- `template.html`
- `README.md`

You can do this via:
- **GitHub web interface**: Click "Add file" > "Upload files"
- **Git command line**: Clone, add files, commit, push

### Step 3: Enable GitHub Pages

1. Go to your repository **Settings**
2. Click **Pages** in the left sidebar
3. Under "Build and deployment":
   - Source: **GitHub Actions**
4. Save

### Step 4: Run the Scraper

The scraper runs automatically every day at 6 AM UTC, but you can trigger it manually:

1. Go to **Actions** tab
2. Click **Scrape Great Clips Coupons**
3. Click **Run workflow** > **Run workflow**

### Step 5: View Your Website

After the workflow completes (~5-10 minutes), your site will be live at:

```
https://YOUR_USERNAME.github.io/YOUR_REPO_NAME/
```

## ‚öôÔ∏è Configuration

### Change Scraping Schedule

Edit `.github/workflows/scrape.yml`:

```yaml
on:
  schedule:
    # Run at 6 AM UTC daily
    - cron: '0 6 * * *'
    
    # Examples:
    # '0 */6 * * *'   - Every 6 hours
    # '0 12 * * 1'    - Every Monday at noon
    # '0 0 * * *'     - Every day at midnight
```

### Increase Scroll Depth

Edit `scraper.py`:

```python
MAX_SCROLLS = 30  # Increase for more ads (slower)
```

## üîß Troubleshooting

### "No offer URLs found"

Facebook may be blocking the scraper. The workflow will retry automatically the next day.

### Website not updating

1. Check the **Actions** tab for errors
2. Make sure GitHub Pages is enabled
3. Check that the `docs/` folder exists with `index.html`

### Rate limiting

GitHub Actions has limits:
- 2,000 minutes/month for free accounts
- Each run takes ~10-15 minutes

## üìä How It Works

1. **GitHub Actions** starts the workflow on schedule
2. **Playwright** opens a headless Chrome browser
3. **Facebook Ad Library** is scraped for Great Clips ads
4. **Each coupon URL** is visited to extract details
5. **Data is saved** to `data/coupons.json`
6. **Website is generated** from the template
7. **GitHub Pages** deploys the website

## üÜì Cost

**$0** - Everything uses free tiers:
- GitHub Actions: Free for public repos
- GitHub Pages: Free hosting
- No API keys needed

## üìù License

MIT - Feel free to use and modify!
